@inproceedings{haetinger2020regularized,
  title={Regularized Kelvinlet Inversion for Real-Time Image Deformation and Video Time Warping},
  author={Haetinger, Guilherme G and Gastal, Eduardo SL},
  booktitle={2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},
  pages={124--131},
  year={2020},
  organization={IEEE}
}

@article{de_goes_regularized_2017,
	title = {Regularized kelvinlets: sculpting brushes based on fundamental solutions of elasticity},
	volume = {36},
	issn = {07300301},
	shorttitle = {Regularized kelvinlets},
	doi = {10.1145/3072959.3073595},
	language = {english},
	number = {4},
	urldate = {2019-12-13},
	journal = {ACM Transactions on Graphics},
	author = {De Goes, Fernando and James, Doug L.},
	month = jul,
	year = {2017},
	pages = {1--11},
	file = {De Goes and James - 2017 - Regularized kelvinlets sculpting brushes based on.pdf:/home/dewey/.zotero/storage/WBLI5BCQ/De Goes and James - 2017 - Regularized kelvinlets sculpting brushes based on.pdf:application/pdf}
}

@article{solteszova_memento_2020,
	title = {Memento: {Localized} {Time}-{Warping} for {Spatio}-{Temporal} {Selection}},
	volume = {39},
	issn = {1467-8659},
	shorttitle = {Memento},
	doi = {10.1111/cgf.13763},
	abstract = {Interaction techniques for temporal data are often focused on affecting the spatial aspects of the data, for instance through the use of transfer functions, camera navigation or clipping planes. However, the temporal aspect of the data interaction is often neglected. The temporal component is either visualized as individual time steps, an animation or a static summary over the temporal domain. When dealing with streaming data, these techniques are unable to cope with the task of re-viewing an interesting local spatio-temporal event, while continuing to observe the rest of the feed. We propose a novel technique that allows users to interactively specify areas of interest in the spatio-temporal domain. By employing a time-warp function, we are able to slow down time, freeze time or even travel back in time, around spatio-temporal events of interest. The combination of such a (pre-defined) time-warp function and brushing directly in the data to select regions of interest allows for a detailed review of temporally and spatially localized events, while maintaining an overview of the global spatio-temporal data. We demonstrate the utility of our technique with several usage scenarios.},
	language = {english},
	number = {1},
	urldate = {2020-06-08},
	journal = {Computer Graphics Forum},
	author = {Solteszova, V. and Smit, N. N. and Stoppel, S. and Grüner, R. and Bruckner, S.},
	year = {2020},
	keywords = {• Human-centred computing → Visualization techniques, • Mathematics of computing → Time series analysis, interaction, Scientific visualization, spatio-temporal projection, temporal data, visualization},
	pages = {231--243},
	file = {Snapshot:/home/dewey/.zotero/storage/ITX5MPQC/cgf.html:text/html;Full Text PDF:/home/dewey/.zotero/storage/DWR37YKS/Solteszova et al. - 2020 - Memento Localized Time-Warping for Spatio-Tempora.pdf:application/pdf}
}

@article{bach_time_2016,
	title = {Time {Curves}: {Folding} {Time} to {Visualize} {Patterns} of {Temporal} {Evolution} in {Data}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {Time {Curves}},
	doi = {10.1109/TVCG.2015.2467851},
	abstract = {We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be deﬁned, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.},
	language = {english},
	number = {1},
	urldate = {2020-06-08},
	journal = {IEEE TVCG},
	author = {Bach, Benjamin and Shi, Conglei and Heulot, Nicolas and Madhyastha, Tara and Grabowski, Tom and Dragicevic, Pierre},
	year = {2016},
	file = {Bach et al. - 2016 - Time Curves Folding Time to Visualize Patterns of.pdf:/home/dewey/.zotero/storage/U73ZZHXB/Bach et al. - 2016 - Time Curves Folding Time to Visualize Patterns of.pdf:application/pdf}
}

@article{rav-acha_evolving_nodate,
	title = {Evolving {Time} {Fronts}: {Spatio}-{Temporal} {Video} {Warping}},
	abstract = {We present evolving time fronts, a new framework for spatiotemporal warping of video. The proposed framework is simple yet general, allowing a large variety of spatio-temporal warps to be speciﬁed in an intuitive manner. Speciﬁcally, we manipulate the time ﬂow of a video sequence by sweeping an evolving time front surface through the video’s aligned space-time volume. In this paper we ﬁrst introduce the general framework, and then describe and discuss several speciﬁc strategies for time front evolution that we have experimented with so far. These strategies are demonstrated to produce a variety of interesting and useful operations on video, ranging from subtle timing changes to eye-catching special effects, creation of dynamic panoramic mosaics, and parallax effects.},
	language = {english},
	author = {Rav-Acha, Alex and Pritch, Yael and Lischinski, Dani and Peleg, Shmuel},
	booktitle={Proc. 32nd Int. Conf. Comput. Graph. Interactive Tech},
	journal={Proc. 32nd Int. Conf. Comput. Graph. Interactive Tech},
	pages = {8},
	file = {Rav-Acha et al. - Evolving Time Fronts Spatio-Temporal Video Warpin.pdf:/home/dewey/.zotero/storage/BKL5ALZQ/Rav-Acha et al. - Evolving Time Fronts Spatio-Temporal Video Warpin.pdf:application/pdf},
	year = {2005}
}

@article{de_goes_dynamic_2018,
	title = {Dynamic kelvinlets: secondary motions based on fundamental solutions of elastodynamics},
	volume = {37},
	issn = {0730-0301, 1557-7368},
	shorttitle = {Dynamic kelvinlets},
	doi = {10.1145/3197517.3201280},
	language = {english},
	number = {4},
	urldate = {2020-06-08},
	journal = {ACM Transactions on Graphics},
	author = {De Goes, Fernando and James, Doug L.},
	month = aug,
	year = {2018},
	pages = {1--10},
	file = {De Goes and James - 2018 - Dynamic kelvinlets secondary motions based on fun.pdf:/home/dewey/.zotero/storage/U3I7HCL5/De Goes and James - 2018 - Dynamic kelvinlets secondary motions based on fun.pdf:application/pdf}
}

@inproceedings{Klein2002,
  title={Stylized video cubes},
  author={Klein, Allison W and Sloan, Peter-Pike J and Finkelstein, Adam and Cohen, Michael F},
  booktitle={SIGGRAPH/EG Symp. on Comput. Animation},
  year={2002}
}

@inproceedings{schodl_video_2000,
	address = {USA},
	series = {{SIGGRAPH} '00},
	title = {Video textures},
	isbn = {978-1-58113-208-3},
	doi = {10.1145/344779.345012},
	abstract = {This paper introduces a new type of medium, called a video texture, which has qualities somewhere between those of a photograph and a video. A video texture provides a continuous infinitely varying stream of images. While the individual frames of a video texture may be repeated from time to time, the video sequence as a whole is never repeated exactly. Video textures can be used in place of digital photos to infuse a static image with dynamic qualities and explicit actions. We present techniques for analyzing a video clip to extract its structure, and for synthesizing a new, similar looking video of arbitrary length. We combine video textures with view morphing techniques to obtain 3D video textures. We also introduce video-based animation, in which the synthesis of video textures can be guided by a user through high-level interactive controls. Applications of video textures and their extensions include the display of dynamic scenes on web pages, the creation of dynamic backdrops for special effects and games, and the interactive control of video-based animation.},
	urldate = {2020-06-08},
	booktitle = {SIGGRAPH},
	author = {Schödl, Arno and Szeliski, Richard and Salesin, David H. and Essa, Irfan},
	month = jul,
	year = {2000},
	keywords = {animation, image-based rendering, morphing, multimedia, natural phenomena, texture synthesis, video sprites, video-based animation, video-based rendering, view morphing},
	pages = {489--498},
	file = {Full Text PDF:/home/dewey/.zotero/storage/ZQPYG9A2/Schödl et al. - 2000 - Video textures.pdf:application/pdf}
}

@inproceedings{zhou_time-mapping_2014,
	title = {Time-{Mapping} {Using} {Space}-{Time} {Saliency}},
	doi = {10.1109/CVPR.2014.429},
	abstract = {We describe a new approach for generating regular-speed, low-frame-rate (LFR) video from a high-frame-rate (HFR) input while preserving the important moments in the original. We call this time-mapping, a time-based analogy to high dynamic range to low dynamic range spatial tone-mapping. Our approach makes these contributions: (1) a robust space-time saliency method for evaluating visual importance, (2) a re-timing technique to temporally resample based on frame importance, and (3) temporal filters to enhance the rendering of salient motion. Results of our space-time saliency method on a benchmark dataset show it is state-of-the-art. In addition, the benefits of our approach to HFR-to-LFR time-mapping over more direct methods are demonstrated in a user study.},
	booktitle = {CVPR},
	author = {Zhou, Feng and Kang, Sing Bing and Cohen, Michael F.},
	month = jun,
	year = {2014},
	keywords = {Cameras, Computational modeling, frame importance, HFR-to-LFR time-mapping, Image color analysis, image motion analysis, low-frame-rate video, Noise, regular-speed video, rendering (computer graphics), retiming technique, robust space-time saliency method, salient motion rendering, Smoothing methods, spatial tone-mapping, Streaming media, temporal filter, time-based analogy, video signal processing, visual importance, Visualization},
	pages = {3358--3365},
	file = {IEEE Xplore Abstract Record:/home/dewey/.zotero/storage/GWDWTEZW/6909825.html:text/html;Submitted Version:/home/dewey/.zotero/storage/MYENAMY7/Zhou et al. - 2014 - Time-Mapping Using Space-Time Saliency.pdf:application/pdf}
}

@inproceedings{wylie_tetrahedral_2002,
	title = {Tetrahedral projection using vertex shaders},
	isbn = {978-0-7803-7641-0},
	doi = {10.1109/SWG.2002.1226504},
	abstract = {Projective methods for volume rendering currently represent the best approach for interactive visualization of unstructured datasets. We present a technique for tetrahedral projection using the programmable vertex shaders on current generation commodity graphics cards. The technique is based on Shirley and Tuchman’s Projected Tetrahedra (PT) algorithm and allows tetrahedral elements to be volume scan converted within the graphics processing unit. Our technique requires no preprocessing of the data and no additional data structures. Our initial implementation allows interactive viewing of large unstructured datasets on a desktop personal computer.},
	language = {english},
	urldate = {2020-06-13},
	booktitle = {Symp. on {Vol.} {Vis.} and {Graph.}},
	author = {Wylie, B. and Moreland, K. and Fisk, L.A. and Crossno, P.},
	year = {2002},
	pages = {7--12},
	file = {TetrahedralProjectionVertexShader.pdf:/home/dewey/Dropbox/AcademicArticles/ComputerGraphics/TetrahedralProjectionVertexShader.pdf:application/pdf}
}

@article{silva_survey_2005,
	title = {A {Survey} of {GPU}-{Based} {Volume} {Rendering} of {Unstructured} {Grids}},
    vol = {12},
    number = {2},
	journal={Revista de inform{\'a}tica te{\'o}rica e aplicada},
	abstract = {Real-time rendering of large unstructured meshes is a major research goal in the scientiﬁc visualization community. While, for regular grids, texture-based techniques are well-suited for current Graphics Processing Units (GPUs), the steps necessary for rendering unstructured meshes are not so easily mapped to current hardware. This paper reviews volume rendering algorithm and techniques for unstructured grids aimed at exploiting high-performance GPUs. We discuss both the algorithms and their implementation details, including major shortcomings of existing approaches.},
	language = {english},
	author = {Silva, Cláudio T and Comba, João L D and Callahan, Steven P and Bernardon, Fabio F},
	year = {2005},
	pages = {9--29},
	file = {surveyOfGPUVolumeRendering.pdf:/home/dewey/Dropbox/AcademicArticles/ComputerGraphics/surveyOfGPUVolumeRendering.pdf:application/pdf}
}

@article{frey_spatio-temporal_2018,
	title = {Spatio-{Temporal} {Contours} from {Deep} {Volume} {Raycasting}},
	volume = {37},
	issn = {1467-8659},
	doi = {10.1111/cgf.13438},
	abstract = {We visualize contours for spatio-temporal processes to indicate where and when non-continuous changes occur or spatial bounds are encountered. All time steps are comprised densely in one visualization, with contours allowing to efficiently analyze processes in the data even in case of spatial or temporal overlap. Contours are determined on the basis of deep raycasting that collects samples across time and depth along each ray. For each sample along a ray, its closest neighbors from adjacent rays are identified, considering time, depth, and value in the process. Large distances are represented as contours in image space, using color to indicate temporal occurrence. This contour representation can easily be combined with volume rendering-based techniques, providing both full spatial detail for individual time steps and an outline of the whole time series in one view. Our view-dependent technique supports efficient progressive computation, and requires no prior assumptions regarding the shape or nature of processes in the data. We discuss and demonstrate the performance and utility of our approach via a variety of data sets, comparison and combination with an alternative technique, and feedback by a domain scientist.},
	language = {english},
	number = {3},
	urldate = {2020-06-13},
	journal = {Computer Graphics Forum},
	author = {Frey, S.},
	year = {2018},
	keywords = {Scientific visualization, •Human-centered computing → Visualization techniques, CCS Concepts},
	pages = {513--524},
	file = {Snapshot:/home/dewey/.zotero/storage/DZDL6BM5/cgf.html:text/html;Full Text PDF:/home/dewey/.zotero/storage/X94QILJN/Frey - 2018 - Spatio-Temporal Contours from Deep Volume Raycasti.pdf:application/pdf}
}

@article{kaufmann_finite_2013,
	title = {Finite {Element} {Image} {Warping}},
	volume = {32},
	issn = {1467-8659},
	doi = {10.1111/cgf.12023},
	abstract = {We introduce a single unifying framework for a wide range of content-aware image warping tasks using a finite element method (FEM). Existing approaches commonly define error terms over vertex finite differences and can be expressed as a special case of our general FEM model. In this work, we exploit the full generality of FEMs, gaining important advantages over prior methods. These advantages include arbitrary mesh connectivity allowing for adaptive meshing and efficient large-scale solutions, a well-defined continuous problem formulation that enables clear analysis of existing warping error functions and allows us to propose improved ones, and higher order basis functions that allow for smoother warps with fewer degrees of freedom. To support per-element basis functions of varying degree and complex mesh connectivity with hanging nodes, we also introduce a novel use of discontinuous Galerkin FEM. We demonstrate the utility of our method by showing examples in video retargeting and camera stabilization applications, and compare our results with previous state of the art methods.},
	language = {english},
	number = {2pt1},
	urldate = {2020-06-14},
	journal = {Computer Graphics Forum},
	author = {Kaufmann, Peter and Wang, Oliver and Sorkine‐Hornung, Alexander and Sorkine‐Hornung, Olga and Smolic, Aljoscha and Gross, Markus},
	year = {2013},
	pages = {31--39},
	file = {Snapshot:/home/dewey/.zotero/storage/NEVMMJSE/cgf.html:text/html}
}

@article{yuefeng_zhang_fuzzy_1996,
	title = {A fuzzy approach to digital image warping},
	volume = {16},
	issn = {1558-1756},
	doi = {10.1109/38.511850},
	abstract = {Digital image warping addresses the problem of how to smoothly transform one digital image into another. The warping process has wide applications in computer animation and can be divided into two classes depending on the type of images being transformed. Gray image warping considers the transformation of one gray-scale image into another-a process also known as image metamorphosis. Binary image warping, on the other hand, addresses the transformation of binary images such as polygonal shapes. The focus in this article is on warping polygons. We can approach the warping of polygonal shapes in two steps. The first establishes a correspondence between the vertices of two given polygons. The second step interpolates the corresponding vertices to generate vertices of an intermediate polygon. This article presents new approaches to both steps. This new algorithm uses fuzzy techniques to warp polygons that have different locations, orientations, sizes and numbers of vertices. The algorithm is robust and extensible to curved shapes.},
	number = {4},
	journal = {IEEE Computer Graphics and Applications},
	author = {Yuefeng Zhang},
	month = jul,
	year = {1996},
	keywords = {binary image warping, computer animation, curved shapes, digital image warping, Digital images, Ear, fuzzy set theory, Fuzzy sets, fuzzy techniques, gray image warping, gray-scale image transformation, Humans, image metamorphosis, image processing, intermediate polygon, interpolation, Interpolation, Matrix decomposition, morphing, polygonal shapes, robust extensible algorithm, Shape, vertex correspondences},
	pages = {34--41},
	file = {IEEE Xplore Abstract Record:/home/dewey/.zotero/storage/PDXDCN2E/511850.html:text/html}
}

@article{karni_energy-based_2009,
	title = {Energy-{Based} {Image} {Deformation}},
	volume = {28},
	issn = {1467-8659},
	doi = {10.1111/j.1467-8659.2009.01503.x},
	abstract = {We present a general approach to shape deformation based on energy minimization, and applications of this approach to the problems of image resizing and 2D shape deformation. Our deformation energy generalizes that found in the prior art, while still admitting an efficient algorithm for its optimization. The key advantage of our energy function is the flexibility with which the set of “legal transformations” may be expressed; these transformations are the ones which are not considered to be distorting. This flexibility allows us to pose the problems of image resizing and 2D shape deformation in a natural way and generate minimally distorted results. It also allows us to strongly reduce undesirable foldovers or self-intersections. Results of both algorithms demonstrate the effectiveness of our approach.},
	language = {english},
	number = {5},
	urldate = {2020-06-14},
	journal = {Computer Graphics Forum},
	author = {Karni, Z. and Freedman, D. and Gotsman, C.},
	year = {2009},
	keywords = {and, Computer, curve, generation, Generation—Line, Graphics:, I.3.3, Picture/Image},
	file = {Snapshot:/home/dewey/.zotero/storage/3VNCBH9Q/j.1467-8659.2009.01503.html:text/html;Full Text PDF:/home/dewey/.zotero/storage/KVNHVVL8/Karni et al. - 2009 - Energy-Based Image Deformation.pdf:application/pdf}
}

@incollection{avidan_seam_nodate,
  title={Seam carving for content-aware image resizing},
  author={Avidan, Shai and Shamir, Ariel},
  booktitle={ACM SIGGRAPH 2007 papers},
  pages={10--es},
  year={2007}
}

@article{schwarz_non-rigid_2020,
  title={Non-rigid registration using free-form deformations},
  author={Schwarz, Loren Arthur},
  journal={Technische Universit{\"a}t M{\"u}nchen},
  year={2007}
}

@misc{foundation_krita_nodate,
	title = {Krita},
	url = {https://krita.org/en/},
	abstract = {all content and translations are done in the PO files. This is just an empty shell. The other languages have translation pages so they will show up in the language drop-down in the navigation area.},
	language = {en-US},
	urldate = {2020-07-01},
	year = {2020},
	journal = {Krita},
	author = {Foundation, Krita},
	file = {Snapshot:/home/dewey/.zotero/storage/S496L58H/en.html:text/html}
}

@inproceedings{korein_temporal_1983,
	title = {Temporal anti-aliasing in computer generated animation},
	isbn = {978-0-89791-109-2},
	abstract = {The desirability of incorporating temporal anti-aliasing, or motion blur, into computer generated animation is discussed and two algorithms for achieving this effect are described. The first approximates continuous object movement and determines intervals during which each object covers each pixel. Hidden surface removal is then performed, allowing the calculation of visible object intensity functions and subsequent filtering. The second form of algorithm detailed involves supersampling the moving image and then filtering the resulting intensity function to “multiply-expose” each output picture. The effects of filter types and the relationship of the algorithms to forms of spatial anti-aliasing are discussed.},
	urldate = {2020-07-06},
	booktitle = {SIGGRAPH},
	author = {Korein, Jonathan and Badler, Norman},
	month = jul,
	year = {1983},
	pages = {377--388},
	file = {Full Text PDF:/home/dewey/.zotero/storage/PHMC5HU5/Korein and Badler - 1983 - Temporal anti-aliasing in computer generated anima.pdf:application/pdf}
}

@article{finlay_speed_1987,
	title = {Speed of apparent motion and the wagon-wheel effect},
	volume = {41},
	issn = {0031-5117, 1532-5962},
	language = {english},
	number = {1},
	urldate = {2020-07-06},
	journal = {Perception \& Psychophysics},
	author = {Finlay, David J. and Dodwell, Peter C.},
	year = {1987},
	file = {Finlay and Dodwell - 1987 - Speed of apparent motion and the wagon-wheel effec.pdf:/home/dewey/.zotero/storage/JJWXVICF/Finlay and Dodwell - 1987 - Speed of apparent motion and the wagon-wheel effec.pdf:application/pdf}
}

@inproceedings{grant_integrated_1985,
	title = {Integrated analytic spatial and temporal anti-aliasing for polyhedra in 4-space},
	isbn = {978-0-89791-166-5},
	abstract = {A visible surface algorithm with integrated analytic spatial and temporal anti-aliasing is presented. This algorithm models moving polygons as four dimensional (X,Y,Z,T) image space polyhedra, where time (T) is treated as an additional spatial dimension. The linearity of these primitives allows simplification of the analytic algorithms. The algorithm is exact for non-intersecting primitives, and exact for the class of intersecting primitives generated by translation and scaling of 3-d (X,Y,Z) polygons in image space. This algorithm is an extension of Catmull's analytic visible surface algorithm for independent pixel processing, based on the outline of integrated spatial and temporal anti-aliasing given by Korien and Badler. An analytic solution requires that the visible surface calculations produce a continuous representation of visible primitives in the time and space dimensions. Visible surface algorithm, graphical primitives, and filtering algorithm, (by Feibush, Levoy and Cook) are extended to include continuous representation of the additional dimension of time. A performance analysis of the algorithm contrasted with a non-temporally anti-aliased version is given.},
	urldate = {2020-07-06},
	booktitle = {SIGGRAPH},
	author = {Grant, Charles W.},
	month = jul,
	year = {1985},
	keywords = {anti-aliasing, filtering algorithms, motion blur, scan-line algorithms, temporal anti-aliasing, visible surface algorithms},
	pages = {79--84},
	file = {Full Text PDF:/home/dewey/.zotero/storage/XFDBSBA8/Grant - 1985 - Integrated analytic spatial and temporal anti-alia.pdf:application/pdf}
}

@article{bolles_epipolar-plane_1987,
	title = {Epipolar-plane image analysis: {An} approach to determining structure from motion},
	volume = {1},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Epipolar-plane image analysis},
	doi = {10.1007/BF00128525},
	abstract = {We present a technique for building a three-dimensional description of a static scene from a dense sequence of images. These images are taken in such rapid succession that they form a solid block of data in which the temporal continuity from image to image is approximately equal to the spatial continuity in an individual image. The technique utilizes knowledge of the camera motion to form and analyze slices of this solid. These slices directly encode not only the three-dimensional positions of objects, but also such spatiotemporal events as the occlusion of one object by another. For straight-line camera motions, these slices have a simple linear structure that makes them easier to analyze. The analysis computes the threedimensional positions of object features, marks occlusion boundaries on the objects, and builds a threedimensional map of "free space." In our article, we first describe the application of this technique to a simple camera motion, and then show how projective duality is used to extend the analysis to a wider class of camera motions and object types that include curved and moving objects.},
	language = {english},
	number = {1},
	urldate = {2020-07-06},
	journal = {International Journal of Computer Vision},
	author = {Bolles, Robert C. and Baker, H. Harlyn and Marimont, David H.},
	year = {1987},
	pages = {7--55},
	file = {Bolles et al. - 1987 - Epipolar-plane image analysis An approach to dete.pdf:/home/dewey/.zotero/storage/I6JEMQGR/Bolles et al. - 1987 - Epipolar-plane image analysis An approach to dete.pdf:application/pdf}
}

@article{bezanson2017julia,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM review},
  volume={59},
  number={1},
  year={2017},
  publisher={SIAM},
}

@article{WolbergAndBoult1989,
author = {Wolberg, G. and Boult, T. E.},
title = {Separable Image Warping with Spatial Lookup Tables},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0097-8930},
journal = {SIGGRAPH},
month = jul,
pages = {369–378},
numpages = {10}
}

@article{Heckbert1989,
  title={Fund. of texture mapping and image warping},
  author={Heckbert, Paul S},
  year={1989},
  publisher={Citeseer}
}

@article{GlasbeyAndMardia1998,
author = {C. A. Glasbey and K. V. Mardia},
title = {A review of image-warping methods},
journal = {Journal of Applied Statistics},
volume = {25},
number = {2},
pages = {155-171},
year = {1998},
publisher = {Taylor & Francis},
}

@misc{noauthor_transform_nodate,
	title = {Transform {Tool} — {Krita} {Manual} version 4.3.0},
	url = {https://docs.krita.org/en/reference_manual/tools/transform.html},
	urldate = {2020-07-07},
	year = {2020},
	file = {Transform Tool — Krita Manual version 4.3.0:/home/dewey/.zotero/storage/ACC36JX2/transform.html:text/html}
}

@inproceedings{Gascon2013,
  title={Fast deformation of volume data using tetrahedral mesh rasterization},
  author={Gascon, Jorge and Espadero, Jose M and Perez, Alvaro G and Torres, Rosell and Otaduy, Miguel A},
  booktitle={SIGGRAPH/EG Symp. on Comput. Animation},
  pages={181--185},
  year={2013}
}

@book{Solomon2015,
	title = {Numerical algorithms: methods for computer vision, machine learning, and graphics},
	isbn = {978-1-4822-5188-3},
	shorttitle = {Numerical algorithms},
	publisher = {CRC Press, Taylor \& Francis Group},
	author = {Solomon, Justin},
	year = {2015},
	keywords = {Computer algorithms, Computer vision, Image processing, Machine learning},
	annote = {"An A K Peters Book."},
	annote = {"I think it's one of best "advanced introduction" books on numerical methods" - Amazon Review},
	file = {Solomon_2015_CRC Press, Taylor & Francis Group_Numerical algorithms.pdf:/home/eduardo/Dropbox/Library/Zotero/Mathematics/Applied Math/Numerical Methods/Solomon_2015_CRC Press, Taylor & Francis Group_Numerical algorithms.pdf:application/pdf}
}

@book{Szeliski2011,
  title = {Computer {{Vision}}},
  author = {Szeliski, Richard},
  year = {2011},
  publisher = {{Springer London}},
  doi = {10.1007/978-1-84882-935-0},
  isbn = {978-1-84882-934-3 978-1-84882-935-0},
}

@book{Wolberg1990,
  title={{Digital Image Warping}},
  author={Wolberg, George},
  volume={10662},
  year={1990},
  publisher={IEEE computer society press Los Alamitos, CA}
}
